{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817ef5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/master/anaconda3/envs/jbg030/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "sys.path.append('../')\n",
    "from config import config\n",
    "import re\n",
    "import datetime\n",
    "import logging\n",
    "import timeit\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import loader, initializer, preprocessor\n",
    "from sentiment import sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [Path(\"data/\"+file) for file in os.listdir('data')]\n",
    "connection = mysql.connector.connect(host=config.get('HOST'), user=config.get('USERNAME'), password=config.get('PASSWORD'),database=config.get('DATABASE'), allow_local_infile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c3e2-56b5-4f54-b12a-c3e0fb6b5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM tweets ORDER BY timestamp_ms DESC\")\n",
    "tweets = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a481c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_column(connection):\n",
    "    add_column_query = \"\"\"\n",
    "    ALTER TABLE `tweets`\n",
    "    ADD COLUMN `sentiment` FLOAT NULL;\n",
    "    \"\"\"\n",
    "    connection.cursor().execute(add_column_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae654a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sentiment_column(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    id, text = tweet\n",
    "    try:\n",
    "        score = sentiment_score.roberta(text)\n",
    "        return (id, score)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}, Tweet: {id}\", file=sys.stderr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eae6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def update_sentiment_scores(connection):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SELECT `id`, `text` FROM `tweets`\")\n",
    "    tweets = cursor.fetchall()\n",
    "    total_tweets = len(tweets)\n",
    "\n",
    "    counter = 0\n",
    "    elapsed = 0\n",
    "    errors = 0\n",
    "\n",
    "    with Pool() as p:\n",
    "        results = []\n",
    "        for tweet in tweets:\n",
    "            start = timeit.default_timer()\n",
    "            res = process_tweet(tweet)\n",
    "            results.append(res)\n",
    "            duration = timeit.default_timer() - start\n",
    "            elapsed += duration\n",
    "            if counter == 0:\n",
    "                time_remaining = 0  # or some default value\n",
    "            else:\n",
    "                time_remaining = (total_tweets - counter) * (elapsed / counter)\n",
    "            print(f\"Processed {counter} out of {total_tweets} tweets. Estimated time left: {str(datetime.timedelta(seconds=time_remaining))}\")\n",
    "            counter += 1\n",
    "\n",
    "    # Filter out None results\n",
    "    results = [r for r in results if r is not None]\n",
    "\n",
    "    # Batch update\n",
    "    update_query = \"UPDATE `tweets` SET `sentiment` = CASE `id` \"\n",
    "    for id, score in results:\n",
    "        update_query += f\"WHEN {id} THEN {score} \"\n",
    "    update_query += \"END WHERE `id` IN (\" + \",\".join(str(id) for id, _ in results) + \")\"\n",
    "    cursor.execute(update_query)\n",
    "    connection.commit()\n",
    "    print(\"Database update completed\")\n",
    "\n",
    "update_sentiment_scores(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961ead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 02:33:21 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 956225 ms exceeds timeout 120000 ms\n",
      "24/05/28 02:33:21 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/05/28 02:33:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:33:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 02:34:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 02:34:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:34:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:35:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:36:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:36:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:36:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:36:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:51:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:51:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:51:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:51:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:51:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:51:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 02:52:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:08:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:08:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:09:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:26:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:26:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:26:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:26:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:26:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:26:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:26:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:26:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:27:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:28:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:28:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:28:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:29:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:44:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:44:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:45:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:45:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:45:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:45:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:45:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:45:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:56:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:56:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:56:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/28 03:56:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.101:60753\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/28 03:56:40 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def update_sentiment_scores_spark():\n",
    "    # Create a SparkSession with the MySQL JDBC driver\n",
    "    spark = SparkSession.builder \\\n",
    "        .config(\"spark.jars\", \"/path/to/mysql-connector-java-version-bin.jar\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Read environment variables\n",
    "    host = os.getenv('HOST')\n",
    "    username = os.getenv('USERNAME')\n",
    "    password = os.getenv('PASSWORD')\n",
    "    database = os.getenv('DATABASE')\n",
    "\n",
    "    # JDBC connection string\n",
    "    url = f\"jdbc:mysql://{host}:3306/{database}?user={username}&password={password}\"\n",
    "\n",
    "    # Load the tweets into a DataFrame\n",
    "    df = spark.read.jdbc(url=url, table=\"tweets\")\n",
    "\n",
    "    # Define a UDF to calculate the sentiment score\n",
    "    sentiment_score_udf = udf(lambda text: sentiment_score.roberta(text), FloatType())\n",
    "\n",
    "    # Calculate the sentiment scores\n",
    "    df = df.withColumn(\"sentiment\", sentiment_score_udf(df[\"text\"]))\n",
    "\n",
    "    # Write the updated DataFrame back to the database\n",
    "    df.write.jdbc(url=url, table=\"tweets\", mode=\"overwrite\")\n",
    "\n",
    "update_sentiment_scores_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sentiment_scores(connection):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SELECT `id`, `text` FROM `tweets`\")\n",
    "    tweets = cursor.fetchall()\n",
    "\n",
    "    counter = 0\n",
    "    elapsed = 0\n",
    "    n = len(tweets)\n",
    "    errors = 0\n",
    "\n",
    "    for tweet in tweets:\n",
    "        start = timeit.default_timer()\n",
    "        id, text = tweet\n",
    "        try:\n",
    "            score = sentiment_score.roberta(text)\n",
    "            print(f\"üìä Sentiment score: {score}\")\n",
    "            cursor.execute(f\"UPDATE `tweets` SET `sentiment` = {score} WHERE `id` = {id}\")\n",
    "            if counter % round(n/10) == 0:\n",
    "                connection.commit()\n",
    "            print(f\"‚úÖ Tweet {id} updated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}, Tweet: {id}\", file=sys.stderr)\n",
    "            errors += 1\n",
    "\n",
    "        counter += 1\n",
    "        duration = timeit.default_timer() - start\n",
    "        elapsed += duration\n",
    "        time_remaining = (n - counter) * (elapsed / counter)\n",
    "        print(f\"‚èØÔ∏è Process: {(counter/n)*100:.2f}% - #Ô∏è‚É£ {counter}/{n} tweets updated - ‚è≥ Time remaining : {str(datetime.timedelta(seconds=time_remaining))}\")\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "update_sentiment_scores(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea36e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize using LDA or regex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
