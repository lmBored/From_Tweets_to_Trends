{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ef5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import config\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import logging\n",
    "import timeit\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sentiment import sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976884fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "# import time\n",
    "\n",
    "from transformers import logging as transformers_logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "configr = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64887f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label, score = sentiment_score.roberta(\"I work 40 hours a week for me to be this poor\", tokenizer, model, configr)\n",
    "print(label)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(\"I work 40 hours a week for me to be this poor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(host=config.get('HOST'), user=config.get('USERNAME'), password=config.get('PASSWORD'),database=config.get('DATABASE'), allow_local_infile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277c3e2-56b5-4f54-b12a-c3e0fb6b5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM tweets ORDER BY timestamp_ms DESC\")\n",
    "tweets = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a481c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_column(connection):\n",
    "    add_column_query = \"\"\"\n",
    "    ALTER TABLE `tweets`\n",
    "    ADD COLUMN `sentiment` FLOAT NULL;\n",
    "    \"\"\"\n",
    "    connection.cursor().execute(add_column_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae654a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sentiment_column(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    id, text = tweet\n",
    "    try:\n",
    "        score = sentiment_score.roberta(text)\n",
    "        return (id, score)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}, Tweet: {id}\", file=sys.stderr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eae6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def update_sentiment_scores(connection):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SELECT `id`, `text` FROM `tweets`\")\n",
    "    tweets = cursor.fetchall()\n",
    "    total_tweets = len(tweets)\n",
    "\n",
    "    counter = 0\n",
    "    elapsed = 0\n",
    "    errors = 0\n",
    "\n",
    "    with Pool() as p:\n",
    "        results = []\n",
    "        for tweet in tweets:\n",
    "            start = timeit.default_timer()\n",
    "            res = process_tweet(tweet)\n",
    "            results.append(res)\n",
    "            duration = timeit.default_timer() - start\n",
    "            elapsed += duration\n",
    "            if counter == 0:\n",
    "                time_remaining = 0  # or some default value\n",
    "            else:\n",
    "                time_remaining = (total_tweets - counter) * (elapsed / counter)\n",
    "            print(f\"Processed {counter} out of {total_tweets} tweets. Estimated time left: {str(datetime.timedelta(seconds=time_remaining))}\")\n",
    "            counter += 1\n",
    "\n",
    "    # Filter out None results\n",
    "    results = [r for r in results if r is not None]\n",
    "\n",
    "    # Batch update\n",
    "    update_query = \"UPDATE `tweets` SET `sentiment` = CASE `id` \"\n",
    "    for id, score in results:\n",
    "        update_query += f\"WHEN {id} THEN {score} \"\n",
    "    update_query += \"END WHERE `id` IN (\" + \",\".join(str(id) for id, _ in results) + \")\"\n",
    "    cursor.execute(update_query)\n",
    "    connection.commit()\n",
    "    print(\"Database update completed\")\n",
    "\n",
    "update_sentiment_scores(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def update_sentiment_scores_spark():\n",
    "    # Create a SparkSession with the MySQL JDBC driver\n",
    "    spark = SparkSession.builder \\\n",
    "        .config(\"spark.jars\", \"/path/to/mysql-connector-java-version-bin.jar\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Read environment variables\n",
    "    host = os.getenv('HOST')\n",
    "    username = os.getenv('USERNAME')\n",
    "    password = os.getenv('PASSWORD')\n",
    "    database = os.getenv('DATABASE')\n",
    "\n",
    "    # JDBC connection string\n",
    "    url = f\"jdbc:mysql://{host}:3306/{database}?user={username}&password={password}\"\n",
    "\n",
    "    # Load the tweets into a DataFrame\n",
    "    df = spark.read.jdbc(url=url, table=\"tweets\")\n",
    "\n",
    "    # Define a UDF to calculate the sentiment score\n",
    "    sentiment_score_udf = udf(lambda text: sentiment_score.roberta(text), FloatType())\n",
    "\n",
    "    # Calculate the sentiment scores\n",
    "    df = df.withColumn(\"sentiment\", sentiment_score_udf(df[\"text\"]))\n",
    "\n",
    "    # Write the updated DataFrame back to the database\n",
    "    df.write.jdbc(url=url, table=\"tweets\", mode=\"overwrite\")\n",
    "\n",
    "update_sentiment_scores_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sentiment_scores(connection):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SELECT `id`, `text` FROM `tweets`\")\n",
    "    tweets = cursor.fetchall()\n",
    "\n",
    "    counter = 0\n",
    "    elapsed = 0\n",
    "    n = len(tweets)\n",
    "    errors = 0\n",
    "\n",
    "    for tweet in tweets:\n",
    "        start = timeit.default_timer()\n",
    "        id, text = tweet\n",
    "        try:\n",
    "            score = sentiment_score.roberta(text)\n",
    "            print(f\"üìä Sentiment score: {score}\")\n",
    "            cursor.execute(f\"UPDATE `tweets` SET `sentiment` = {score} WHERE `id` = {id}\")\n",
    "            if counter % round(n/10) == 0:\n",
    "                connection.commit()\n",
    "            print(f\"‚úÖ Tweet {id} updated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}, Tweet: {id}\", file=sys.stderr)\n",
    "            errors += 1\n",
    "\n",
    "        counter += 1\n",
    "        duration = timeit.default_timer() - start\n",
    "        elapsed += duration\n",
    "        time_remaining = (n - counter) * (elapsed / counter)\n",
    "        print(f\"‚èØÔ∏è Process: {(counter/n)*100:.2f}% - #Ô∏è‚É£ {counter}/{n} tweets updated - ‚è≥ Time remaining : {str(datetime.timedelta(seconds=time_remaining))}\")\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "update_sentiment_scores(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb491723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b8c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I have an iphone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_task(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
